<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>scan API documentation</title>
<meta name="description" content="Module for scanning and extracting data from aplog-generated files." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>scan</code></h1>
</header>
<section id="section-intro">
<p>Module for scanning and extracting data from aplog-generated files.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34; Module for scanning and extracting data from aplog-generated files.
&#34;&#34;&#34;
import sys, time, argparse, os
from timeit import default_timer as timer
#from pprint import pprint
import bisect
import numpy as np
import msgpack
import msgpack_numpy
msgpack_numpy.patch()
__version__ = &#39;v1.3.0 2021-07-22&#39;

#````````````````````````````Globals``````````````````````````````````````````
Nano = 0.000000001
TimeFormat_in = &#39;%y%m%d_%H%M%S&#39;
TimeFormat_out = &#39;%y%m%d_%H%M%S&#39;
#````````````````````````````Helper functions`````````````````````````````````
def _printv(msg):
    if APScan.Verbosity &gt;= 1:
        print(f&#39;DBG_APSV: {msg}&#39;)
def _printvv(msg):
    if APScan.Verbosity &gt;= 2 :
        print(f&#39;DBG_APSVV: {msg}&#39;)

def _timeInterval(startTime, span):
    &#34;&#34;&#34;returns sections (string) and times (float) of time interval
    boundaries&#34;&#34;&#34;
    ttuple = time.strptime(startTime,TimeFormat_in)
    startSection = time.strftime(TimeFormat_out, ttuple)
    startTime = time.mktime(ttuple)
    endTime = startTime +span
    endTime = min(endTime, 4102462799.)# 2099-12-31
    ttuple = time.localtime(endTime)
    endSection = time.strftime(TimeFormat_out, ttuple)
    _printv(f&#39;start,end:{startSection, endSection}&#39;)
    return startSection, startTime, endSection, endTime
#,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
#````````````````````````````class APView`````````````````````````````````````
class APScan():
    Verbosity = 0
    &#34;&#34;&#34;Show dedugging messages.&#34;&#34;&#34;

    def __init__(self, fileName):
        &#34;&#34;&#34;Open logbook fileName, unpack headers, position file to data sections.&#34;&#34;&#34;

        try:
            self.logbookSize = os.path.getsize(fileName)
        except Exception as e:
            print(f&#39;ERROR opening file {fileName}: {e}&#39;)
            sys.exit()
        self.logbook = open(fileName,&#39;rb&#39;)

        # unpack logbook contents and set file position after it
        self.unpacker = msgpack.Unpacker(self.logbook, use_list=False) #use_list speeds up 20%, # does not help:, read_size=100*1024*1024)
        self.dirSize = 0
        self.directory = []
        for contents in self.unpacker:
            #printvv(f&#39;Table of contents: {contents}&#39;)
            try:
                self.dirSize = contents[&#39;contents&#39;][&#39;size&#39;]
            except:
                print(&#39;Warning: Table of contents is missing or wrong&#39;)
                break
            self.directory = contents[&#39;data&#39;]
            break

        # unpack two sections after the contents: Abstract and Abbreviations
        self.position = self.dirSize
        self.logbook.seek(self.position)
        self.unpacker = msgpack.Unpacker(self.logbook, use_list=False) #use_list speeds up 20%, # does not help:, read_size=100*1024*1024)
        nSections = 0
        for section in self.unpacker:
            #print(f&#39;section:{nSections}&#39;)
            nSections += 1
            if nSections == 1:# section: Abstract
                _printvv(f&#39;Abstract@{self.logbook.tell()}: {section}&#39;)
                self.abstract = section[&#39;abstract&#39;]
                self.compression = self.abstract.get(&#39;compression&#39;)
                if self.compression is None:
                    continue
                if self.compression != &#39;None&#39;:
                    module = __import__(self.compression)
                    self.decompress = module.decompress
                continue
            if nSections == 2:# section: Abbreviations
                self.par2key = section[&#39;abbreviations&#39;]
                self.key2par = {value[0]:key for key,value in self.par2key.items()}
                _printvv(f&#39;Abbreviations@{self.logbook.tell()}: {self.key2par}&#39;)                
                break

    def get_headers(self):
        &#34;&#34;&#34;Returns dict of header sections: Directory, Abstract, Abbreviations&#34;&#34;&#34;
        return {&#39;Directory&#39;:self.directory, &#39;Abstract&#39;:self.abstract
        , &#39;Abbreviations&#39;:self.key2par}

    def extract_objects(self, span=0., items=[], startTime=None):
        &#34;&#34;&#34;
        Returns correlated dict of times and values of the logged items during
        the selected time interval.
        
        **span**:   Time interval for data extraction in seconds. If 0, then the
                        data will be extracted starting from the startTime and ending 
                        at the end of the logbook.
        
        **items**:  List of items to extract. Item are coded with keys. 
                The mapping of the Process Variables (PV) could be found in
                the self.par2key map. The reversed mapping is in the 
                self.key2par map.
        
        **startTime**: String for selecting start of the extraction interval. 
                Format: YYMMDD_HHMMSS. Set it to None for the logbook beginning. 
                &#34;&#34;&#34;
        extracted = {}
        parameterStatistics = {}

        if len(items) == 0: # enable handling of all items 
            items = self.key2par.keys()
        for key,par in self.key2par.items():
            if par not in parameterStatistics:
                #print(f&#39;add to stat[{len(parameterStatistics)+1}]: {par}&#39;) 
                parameterStatistics[key] = 0
            if par not in extracted and key in items:
                    _printvv(f&#39;add to graph[{len(extracted)+1}]: {par}&#39;) 
                    extracted[key] = {&#39;par&#39;:par, &#39;time&#39;:[], &#39;value&#39;:[]}
        
        if startTime is not None:
            startSection, startTStamp, endSection, endTime\
            = _timeInterval(startTime, span)

        # re-create the unpacker for reading logbook starting from required section
        if len(self.directory) != 0 and startTime:
            keys = list(self.directory.keys())
            nearest_idx = bisect.bisect_left(keys, startSection)
            if keys[nearest_idx] != startSection:
                startSection = keys[nearest_idx-1]
            _printvv(f&#39;start section {startSection, startTStamp, endTime}&#39;)
            self.position = self.directory[startSection]
            self.logbook.seek(self.position)
            _printvv(f&#39;logbook positioned to section {startSection}, offset={self.dirSize}&#39;)
            self.unpacker = msgpack.Unpacker(self.logbook, use_list=False) #use_list speeds up 20%, # does not help:, read_size=100*1024*1024)

        # loop over sections in the logbook
        tstart = time.time()
        nSections = 0
        nParagraphs = 0
        reached_endTime = False
        for section in self.unpacker:
            if reached_endTime:
                break
            nSections += 1
            # data sections
            #print(f&#39;Data Section: {nSections}&#39;)
            dt = time.time() - tstart
            if nSections%60 == 0:
                _printv((f&#39;Data sections: {nSections}, paragraphs: {nParagraphs}&#39;
                f&#39;, elapsed time: {round(dt,1)}, paragraphs/s: {nParagraphs//dt}&#39;))
            try:
                if self.compression != &#39;None&#39;:
                    decompressed = self.decompress(section)
                    section = msgpack.unpackb(decompressed)
                sectionDatetime, paragraphs = section
            except Exception as e:
                print(f&#39;WARNING: wrong section {nSections}: {str(section)[:75]}...&#39;, {e})
                break
            if startTime is None:
                startSection, startTStamp, endSection, endTime\
                = _timeInterval(sectionDatetime, span)
                startTime = startTStamp
                
            if sectionDatetime &gt; endSection:
                _printvv(f&#39;reached last section {sectionDatetime}&#39;)
            nParagraphs += len(paragraphs)

            # iterate paragraphs 
            try:
                for timestamp,parkeys in paragraphs:
                    timestamp *= Nano
                    #print(f&#39;paragraph: {timestamp}&#39;)#, parkeys}&#39;)
                    if timestamp &lt; startTStamp:
                        continue
                    if timestamp &gt; endTime:
                        _printvv(f&#39;reached endTime {endTime}&#39;)
                        reached_endTime =True
                        break
                    for key in parkeys:
                        if key not in items:
                            continue
                        parameterStatistics[key] += 1
                        values = parkeys[key]
                        try:    nVals = len(values)
                        except: values = [values] # make it subscriptable
                        par = self.key2par[key]
                        # if values is a vector then append all its points spaced by 1 us
                        for i,v in enumerate(values):
                            extracted[key][&#39;time&#39;].append(timestamp + i*1.e-6)
                            extracted[key][&#39;value&#39;].append(v)
                            #print(f&#39;key {key}, ts: {timestamp}&#39;)
            except Exception as e:
                print(f&#39;WARNING: wrong paragraph {nParagraphs}: {e}&#39;)

        print(f&#39;Deserialized from {self.logbook.name}: {nSections} sections, {nParagraphs} paragraphs&#39;)
        print(f&#39;Point/Parameter: {parameterStatistics}&#39;)
        dt = time.time() - tstart
        mbps = f&#39;, {round((self.logbook.tell() - self.position)/1e6/dt,1)} MB/s&#39;
        print((f&#39;Elapsed time: {round(dt,1)} s, {int(nParagraphs/dt)}&#39;
        f&#39; paragraphs/s&#39;)+mbps)
        return extracted</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="scan.APScan"><code class="flex name class">
<span>class <span class="ident">APScan</span></span>
<span>(</span><span>fileName)</span>
</code></dt>
<dd>
<div class="desc"><p>Open logbook fileName, unpack headers, position file to data sections.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class APScan():
    Verbosity = 0
    &#34;&#34;&#34;Show dedugging messages.&#34;&#34;&#34;

    def __init__(self, fileName):
        &#34;&#34;&#34;Open logbook fileName, unpack headers, position file to data sections.&#34;&#34;&#34;

        try:
            self.logbookSize = os.path.getsize(fileName)
        except Exception as e:
            print(f&#39;ERROR opening file {fileName}: {e}&#39;)
            sys.exit()
        self.logbook = open(fileName,&#39;rb&#39;)

        # unpack logbook contents and set file position after it
        self.unpacker = msgpack.Unpacker(self.logbook, use_list=False) #use_list speeds up 20%, # does not help:, read_size=100*1024*1024)
        self.dirSize = 0
        self.directory = []
        for contents in self.unpacker:
            #printvv(f&#39;Table of contents: {contents}&#39;)
            try:
                self.dirSize = contents[&#39;contents&#39;][&#39;size&#39;]
            except:
                print(&#39;Warning: Table of contents is missing or wrong&#39;)
                break
            self.directory = contents[&#39;data&#39;]
            break

        # unpack two sections after the contents: Abstract and Abbreviations
        self.position = self.dirSize
        self.logbook.seek(self.position)
        self.unpacker = msgpack.Unpacker(self.logbook, use_list=False) #use_list speeds up 20%, # does not help:, read_size=100*1024*1024)
        nSections = 0
        for section in self.unpacker:
            #print(f&#39;section:{nSections}&#39;)
            nSections += 1
            if nSections == 1:# section: Abstract
                _printvv(f&#39;Abstract@{self.logbook.tell()}: {section}&#39;)
                self.abstract = section[&#39;abstract&#39;]
                self.compression = self.abstract.get(&#39;compression&#39;)
                if self.compression is None:
                    continue
                if self.compression != &#39;None&#39;:
                    module = __import__(self.compression)
                    self.decompress = module.decompress
                continue
            if nSections == 2:# section: Abbreviations
                self.par2key = section[&#39;abbreviations&#39;]
                self.key2par = {value[0]:key for key,value in self.par2key.items()}
                _printvv(f&#39;Abbreviations@{self.logbook.tell()}: {self.key2par}&#39;)                
                break

    def get_headers(self):
        &#34;&#34;&#34;Returns dict of header sections: Directory, Abstract, Abbreviations&#34;&#34;&#34;
        return {&#39;Directory&#39;:self.directory, &#39;Abstract&#39;:self.abstract
        , &#39;Abbreviations&#39;:self.key2par}

    def extract_objects(self, span=0., items=[], startTime=None):
        &#34;&#34;&#34;
        Returns correlated dict of times and values of the logged items during
        the selected time interval.
        
        **span**:   Time interval for data extraction in seconds. If 0, then the
                        data will be extracted starting from the startTime and ending 
                        at the end of the logbook.
        
        **items**:  List of items to extract. Item are coded with keys. 
                The mapping of the Process Variables (PV) could be found in
                the self.par2key map. The reversed mapping is in the 
                self.key2par map.
        
        **startTime**: String for selecting start of the extraction interval. 
                Format: YYMMDD_HHMMSS. Set it to None for the logbook beginning. 
                &#34;&#34;&#34;
        extracted = {}
        parameterStatistics = {}

        if len(items) == 0: # enable handling of all items 
            items = self.key2par.keys()
        for key,par in self.key2par.items():
            if par not in parameterStatistics:
                #print(f&#39;add to stat[{len(parameterStatistics)+1}]: {par}&#39;) 
                parameterStatistics[key] = 0
            if par not in extracted and key in items:
                    _printvv(f&#39;add to graph[{len(extracted)+1}]: {par}&#39;) 
                    extracted[key] = {&#39;par&#39;:par, &#39;time&#39;:[], &#39;value&#39;:[]}
        
        if startTime is not None:
            startSection, startTStamp, endSection, endTime\
            = _timeInterval(startTime, span)

        # re-create the unpacker for reading logbook starting from required section
        if len(self.directory) != 0 and startTime:
            keys = list(self.directory.keys())
            nearest_idx = bisect.bisect_left(keys, startSection)
            if keys[nearest_idx] != startSection:
                startSection = keys[nearest_idx-1]
            _printvv(f&#39;start section {startSection, startTStamp, endTime}&#39;)
            self.position = self.directory[startSection]
            self.logbook.seek(self.position)
            _printvv(f&#39;logbook positioned to section {startSection}, offset={self.dirSize}&#39;)
            self.unpacker = msgpack.Unpacker(self.logbook, use_list=False) #use_list speeds up 20%, # does not help:, read_size=100*1024*1024)

        # loop over sections in the logbook
        tstart = time.time()
        nSections = 0
        nParagraphs = 0
        reached_endTime = False
        for section in self.unpacker:
            if reached_endTime:
                break
            nSections += 1
            # data sections
            #print(f&#39;Data Section: {nSections}&#39;)
            dt = time.time() - tstart
            if nSections%60 == 0:
                _printv((f&#39;Data sections: {nSections}, paragraphs: {nParagraphs}&#39;
                f&#39;, elapsed time: {round(dt,1)}, paragraphs/s: {nParagraphs//dt}&#39;))
            try:
                if self.compression != &#39;None&#39;:
                    decompressed = self.decompress(section)
                    section = msgpack.unpackb(decompressed)
                sectionDatetime, paragraphs = section
            except Exception as e:
                print(f&#39;WARNING: wrong section {nSections}: {str(section)[:75]}...&#39;, {e})
                break
            if startTime is None:
                startSection, startTStamp, endSection, endTime\
                = _timeInterval(sectionDatetime, span)
                startTime = startTStamp
                
            if sectionDatetime &gt; endSection:
                _printvv(f&#39;reached last section {sectionDatetime}&#39;)
            nParagraphs += len(paragraphs)

            # iterate paragraphs 
            try:
                for timestamp,parkeys in paragraphs:
                    timestamp *= Nano
                    #print(f&#39;paragraph: {timestamp}&#39;)#, parkeys}&#39;)
                    if timestamp &lt; startTStamp:
                        continue
                    if timestamp &gt; endTime:
                        _printvv(f&#39;reached endTime {endTime}&#39;)
                        reached_endTime =True
                        break
                    for key in parkeys:
                        if key not in items:
                            continue
                        parameterStatistics[key] += 1
                        values = parkeys[key]
                        try:    nVals = len(values)
                        except: values = [values] # make it subscriptable
                        par = self.key2par[key]
                        # if values is a vector then append all its points spaced by 1 us
                        for i,v in enumerate(values):
                            extracted[key][&#39;time&#39;].append(timestamp + i*1.e-6)
                            extracted[key][&#39;value&#39;].append(v)
                            #print(f&#39;key {key}, ts: {timestamp}&#39;)
            except Exception as e:
                print(f&#39;WARNING: wrong paragraph {nParagraphs}: {e}&#39;)

        print(f&#39;Deserialized from {self.logbook.name}: {nSections} sections, {nParagraphs} paragraphs&#39;)
        print(f&#39;Point/Parameter: {parameterStatistics}&#39;)
        dt = time.time() - tstart
        mbps = f&#39;, {round((self.logbook.tell() - self.position)/1e6/dt,1)} MB/s&#39;
        print((f&#39;Elapsed time: {round(dt,1)} s, {int(nParagraphs/dt)}&#39;
        f&#39; paragraphs/s&#39;)+mbps)
        return extracted</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="scan.APScan.Verbosity"><code class="name">var <span class="ident">Verbosity</span></code></dt>
<dd>
<div class="desc"><p>Show dedugging messages.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="scan.APScan.extract_objects"><code class="name flex">
<span>def <span class="ident">extract_objects</span></span>(<span>self, span=0.0, items=[], startTime=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns correlated dict of times and values of the logged items during
the selected time interval.</p>
<p><strong>span</strong>:
Time interval for data extraction in seconds. If 0, then the
data will be extracted starting from the startTime and ending
at the end of the logbook.</p>
<p><strong>items</strong>:
List of items to extract. Item are coded with keys.
The mapping of the Process Variables (PV) could be found in
the self.par2key map. The reversed mapping is in the
self.key2par map.</p>
<p><strong>startTime</strong>: String for selecting start of the extraction interval.
Format: YYMMDD_HHMMSS. Set it to None for the logbook beginning.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_objects(self, span=0., items=[], startTime=None):
    &#34;&#34;&#34;
    Returns correlated dict of times and values of the logged items during
    the selected time interval.
    
    **span**:   Time interval for data extraction in seconds. If 0, then the
                    data will be extracted starting from the startTime and ending 
                    at the end of the logbook.
    
    **items**:  List of items to extract. Item are coded with keys. 
            The mapping of the Process Variables (PV) could be found in
            the self.par2key map. The reversed mapping is in the 
            self.key2par map.
    
    **startTime**: String for selecting start of the extraction interval. 
            Format: YYMMDD_HHMMSS. Set it to None for the logbook beginning. 
            &#34;&#34;&#34;
    extracted = {}
    parameterStatistics = {}

    if len(items) == 0: # enable handling of all items 
        items = self.key2par.keys()
    for key,par in self.key2par.items():
        if par not in parameterStatistics:
            #print(f&#39;add to stat[{len(parameterStatistics)+1}]: {par}&#39;) 
            parameterStatistics[key] = 0
        if par not in extracted and key in items:
                _printvv(f&#39;add to graph[{len(extracted)+1}]: {par}&#39;) 
                extracted[key] = {&#39;par&#39;:par, &#39;time&#39;:[], &#39;value&#39;:[]}
    
    if startTime is not None:
        startSection, startTStamp, endSection, endTime\
        = _timeInterval(startTime, span)

    # re-create the unpacker for reading logbook starting from required section
    if len(self.directory) != 0 and startTime:
        keys = list(self.directory.keys())
        nearest_idx = bisect.bisect_left(keys, startSection)
        if keys[nearest_idx] != startSection:
            startSection = keys[nearest_idx-1]
        _printvv(f&#39;start section {startSection, startTStamp, endTime}&#39;)
        self.position = self.directory[startSection]
        self.logbook.seek(self.position)
        _printvv(f&#39;logbook positioned to section {startSection}, offset={self.dirSize}&#39;)
        self.unpacker = msgpack.Unpacker(self.logbook, use_list=False) #use_list speeds up 20%, # does not help:, read_size=100*1024*1024)

    # loop over sections in the logbook
    tstart = time.time()
    nSections = 0
    nParagraphs = 0
    reached_endTime = False
    for section in self.unpacker:
        if reached_endTime:
            break
        nSections += 1
        # data sections
        #print(f&#39;Data Section: {nSections}&#39;)
        dt = time.time() - tstart
        if nSections%60 == 0:
            _printv((f&#39;Data sections: {nSections}, paragraphs: {nParagraphs}&#39;
            f&#39;, elapsed time: {round(dt,1)}, paragraphs/s: {nParagraphs//dt}&#39;))
        try:
            if self.compression != &#39;None&#39;:
                decompressed = self.decompress(section)
                section = msgpack.unpackb(decompressed)
            sectionDatetime, paragraphs = section
        except Exception as e:
            print(f&#39;WARNING: wrong section {nSections}: {str(section)[:75]}...&#39;, {e})
            break
        if startTime is None:
            startSection, startTStamp, endSection, endTime\
            = _timeInterval(sectionDatetime, span)
            startTime = startTStamp
            
        if sectionDatetime &gt; endSection:
            _printvv(f&#39;reached last section {sectionDatetime}&#39;)
        nParagraphs += len(paragraphs)

        # iterate paragraphs 
        try:
            for timestamp,parkeys in paragraphs:
                timestamp *= Nano
                #print(f&#39;paragraph: {timestamp}&#39;)#, parkeys}&#39;)
                if timestamp &lt; startTStamp:
                    continue
                if timestamp &gt; endTime:
                    _printvv(f&#39;reached endTime {endTime}&#39;)
                    reached_endTime =True
                    break
                for key in parkeys:
                    if key not in items:
                        continue
                    parameterStatistics[key] += 1
                    values = parkeys[key]
                    try:    nVals = len(values)
                    except: values = [values] # make it subscriptable
                    par = self.key2par[key]
                    # if values is a vector then append all its points spaced by 1 us
                    for i,v in enumerate(values):
                        extracted[key][&#39;time&#39;].append(timestamp + i*1.e-6)
                        extracted[key][&#39;value&#39;].append(v)
                        #print(f&#39;key {key}, ts: {timestamp}&#39;)
        except Exception as e:
            print(f&#39;WARNING: wrong paragraph {nParagraphs}: {e}&#39;)

    print(f&#39;Deserialized from {self.logbook.name}: {nSections} sections, {nParagraphs} paragraphs&#39;)
    print(f&#39;Point/Parameter: {parameterStatistics}&#39;)
    dt = time.time() - tstart
    mbps = f&#39;, {round((self.logbook.tell() - self.position)/1e6/dt,1)} MB/s&#39;
    print((f&#39;Elapsed time: {round(dt,1)} s, {int(nParagraphs/dt)}&#39;
    f&#39; paragraphs/s&#39;)+mbps)
    return extracted</code></pre>
</details>
</dd>
<dt id="scan.APScan.get_headers"><code class="name flex">
<span>def <span class="ident">get_headers</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns dict of header sections: Directory, Abstract, Abbreviations</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_headers(self):
    &#34;&#34;&#34;Returns dict of header sections: Directory, Abstract, Abbreviations&#34;&#34;&#34;
    return {&#39;Directory&#39;:self.directory, &#39;Abstract&#39;:self.abstract
    , &#39;Abbreviations&#39;:self.key2par}</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="scan.APScan" href="#scan.APScan">APScan</a></code></h4>
<ul class="">
<li><code><a title="scan.APScan.Verbosity" href="#scan.APScan.Verbosity">Verbosity</a></code></li>
<li><code><a title="scan.APScan.extract_objects" href="#scan.APScan.extract_objects">extract_objects</a></code></li>
<li><code><a title="scan.APScan.get_headers" href="#scan.APScan.get_headers">get_headers</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>